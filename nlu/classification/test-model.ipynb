{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../dataset/data-nottag.set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "colnames=['text', 'tag']\n",
    "def filtered_words(x:tuple):\n",
    "    #w = .lower()#word_tokenize(x[0],custom_dict=o)\n",
    "    #ww = [word for word in w if word not in list(thai_stopwords())]\n",
    "    return (x[0].lower().strip() ,x[1])#(''.join(ww),x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = pd.read_csv(file, names=colnames, header=None,sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 423 entries, 0 to 422\n",
      "Data columns (total 2 columns):\n",
      "text    423 non-null object\n",
      "tag     423 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.7+ KB\n"
     ]
    }
   ],
   "source": [
    "user1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pythainlp.ulmfit import process_thai\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = user1.text\n",
    "y = user1.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.3, random_state=42)#,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB,BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889763779527559\n",
      "0.5905511811023622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7874015748031497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TC\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8740157480314961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TC\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3543307086614173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TC\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968503937007874\n"
     ]
    }
   ],
   "source": [
    "f1=[]\n",
    "report=[]\n",
    "for model in [MultinomialNB(),\n",
    "              BernoulliNB(),\n",
    "              DecisionTreeClassifier(),\n",
    "              RandomForestClassifier(criterion='entropy'),\n",
    "              SVC(),\n",
    "              MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(24, 6), verbose=False, max_iter=2000)\n",
    "             ]:\n",
    "    nb = Pipeline([('vect', CountVectorizer(tokenizer=process_thai, ngram_range=(1,2))),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('chi2', SelectKBest(chi2, k='all')),\n",
    "               ('clf', model),\n",
    "    ])\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    t = accuracy_score(y_pred, y_test)\n",
    "    del nb\n",
    "    print(t)\n",
    "    f1.append(t)\n",
    "    tt=classification_report(y_test, y_pred)\n",
    "    #print(tt)\n",
    "    report.append(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       alert       0.98      1.00      0.99        45\n",
      "     asktime       1.00      1.00      1.00         8\n",
      "         fan       1.00      1.00      1.00         4\n",
      "       light       1.00      1.00      1.00         8\n",
      "       music       1.00      0.86      0.92        14\n",
      "        news       1.00      1.00      1.00         9\n",
      "    religion       0.78      1.00      0.88         7\n",
      "         sos       0.94      1.00      0.97        15\n",
      "     weather       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.97       127\n",
      "   macro avg       0.97      0.97      0.97       127\n",
      "weighted avg       0.97      0.97      0.97       127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       alert       0.94      1.00      0.97        45\n",
      "     asktime       0.88      0.88      0.88         8\n",
      "         fan       1.00      0.75      0.86         4\n",
      "       light       1.00      0.50      0.67         8\n",
      "       music       0.63      0.86      0.73        14\n",
      "        news       1.00      0.56      0.71         9\n",
      "    religion       0.70      1.00      0.82         7\n",
      "         sos       1.00      1.00      1.00        15\n",
      "     weather       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.89       127\n",
      "   macro avg       0.90      0.82      0.84       127\n",
      "weighted avg       0.91      0.89      0.89       127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(24, 6), verbose=False, max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer(tokenizer=process_thai, ngram_range=(1,2))),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('chi2', SelectKBest(chi2, k='all')),\n",
    "               ('clf', model),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function process_th...\n",
       "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                               early_stopping=False, epsilon=1e-08,\n",
       "                               hidden_layer_sizes=(24, 6),\n",
       "                               learning_rate='constant',\n",
       "                               learning_rate_init=0.001, max_iter=2000,\n",
       "                               momentum=0.9, n_iter_no_change=10,\n",
       "                               nesterovs_momentum=True, power_t=0.5,\n",
       "                               random_state=None, shuffle=True, solver='adam',\n",
       "                               tol=0.0001, validation_fraction=0.1,\n",
       "                               verbose=False, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open('../../modelclass2.model', 'wb') as out_strm: \n",
    "    dill.dump(nb, out_strm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
